{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7edc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Incase you don't have these.\"\n",
    "!pip install timm\n",
    "!pip install torchtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b583acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchtyping import TensorType, patch_typeguard\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from typing import Callable, Iterator, Dict\n",
    "from typeguard import typechecked\n",
    "\n",
    "from timm.data import create_dataset\n",
    "\n",
    "patch_typeguard()  # use before @typechecked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8817dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: Downloading required\"\n",
    "\"Get your imagenetmini dataset at:\"\n",
    "\"https://drive.google.com/drive/folders/1oudus89CoG9_7r3twbIhw2K_pgVr0D0X?usp=sharing\"\n",
    "\n",
    "\"Get your pre-trained resnet50 model (supcon.pth) at:\"\n",
    "\"https://www.dropbox.com/s/l4a69ececk4spdt/supcon.pth?dl=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba060f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 448\n",
    "batch_size = 2\n",
    "projection_dim = 128 #128 for imagenette, 64 for CIFAR10\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696f88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Code below loads the imagenetmini data set.\"\n",
    "tim_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "imagenet_ds_test = create_dataset(name = '', root = 'imagenetmini', transform = tim_transform)\n",
    "\n",
    "img_testloader = torch.utils.data.DataLoader(\n",
    "    imagenet_ds_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24950ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed737cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "sd = 'supcon.pth'\n",
    "sd = torch.load(sd, map_location=DEVICE)\n",
    "\n",
    "\"TODO: Implementation required:\"\n",
    "\"Load the pre-trained weights into the resnet50 model, supposedly these pre-trained weights were trained\"\n",
    "\"using the sought-after supervised contrastive losses.\"\n",
    "\"Source: https://github.com/HobbitLong/SupContrast\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3809e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    \n",
    "    feature_vector_blocks = [[] for i in range(4)]\n",
    "\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            \"TODO: Implementation required\"\n",
    "            \"Use the resnet50-model to extract the features from intermediate layers.\"\n",
    "            \"Hint: Check layer 1, 2, 3, 4 in \"\n",
    "            \"https://pytorch.org/vision/0.8/_modules/torchvision/models/resnet.html\"\n",
    "            \n",
    "        h = h.detach()\n",
    "        h_blocks = [h_1, h_2, h_3, h_4]\n",
    "        for j, i in enumerate(h_blocks):\n",
    "            i = i.detach()\n",
    "            feature_vector_blocks[j].extend(i.cpu().detach().numpy())\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())    \n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "            \n",
    "        if step == 22:\n",
    "            break\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    \n",
    "    for i in range(len(feature_vector_blocks)):\n",
    "        feature_vector_blocks[i] = np.array(feature_vector_blocks[i])\n",
    "    \n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector, feature_vector_blocks\n",
    "\n",
    "def get_features(context_model, test_loader, device):\n",
    "    test_X, test_y, test_blocks = inference(test_loader, context_model, device)\n",
    "    return test_X, test_y, test_blocks \n",
    "\n",
    "def create_data_loaders_from_arrays(X_test, y_test, block_test, batch_size):\n",
    "    test1 = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(block_test[0]), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test2 = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(block_test[1]), torch.from_numpy(y_test)\n",
    "    )\n",
    "    \n",
    "    test3 = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(block_test[2]), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test4 = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(block_test[3]), torch.from_numpy(y_test)\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    \n",
    "    return test_loader, test1, test2, test3, test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Creating features from pre-trained context model ###\")\n",
    "test_X, test_y, test_blocks = get_features(model, img_testloader, DEVICE)\n",
    "arr_test_loader, block_1, block_2, block_3, block_4 = create_data_loaders_from_arrays(test_X, test_y, test_blocks, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (images, _) in enumerate(imagenet_ds_test):\n",
    "    if step != 23:\n",
    "        continue\n",
    "    batch = images.cpu().detach().numpy()\n",
    "    batch = np.moveaxis(batch, 0, -1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(batch)\n",
    "    plt.imsave('dog.jpg', batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52202562",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (images, _) in enumerate(block_1):\n",
    "\n",
    "    if step != 23:\n",
    "      continue\n",
    "    print('images.shape:', images.shape)\n",
    "\n",
    "    image = images.cpu().detach().numpy()\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    np.save('superblock1.npy', image)\n",
    "\n",
    "    break\n",
    "\n",
    "for step, (images, _) in enumerate(block_2):\n",
    "    if step != 23:\n",
    "      continue\n",
    "    print('images.shape:', images.shape)\n",
    "    image = images.cpu().detach().numpy()\n",
    "\n",
    "    # put color channels as last dimension \n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    np.save('superblock2.npy', image)\n",
    "    \n",
    "    break\n",
    "\n",
    "for step, (images, _) in enumerate(block_3):\n",
    "    if step != 23:\n",
    "      continue\n",
    "    print('images.shape:', images.shape)\n",
    "    image = images.cpu().detach().numpy()\n",
    "\n",
    "    # put color channels as last dimension \n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    np.save('superblock3.npy', image)\n",
    "\n",
    "    break\n",
    "\n",
    "for step, (images, _) in enumerate(block_4):\n",
    "    if step != 23:\n",
    "      continue\n",
    "    print('images.shape:', images.shape)\n",
    "    image = images.cpu().detach().numpy()\n",
    "\n",
    "    # put color channels as last dimension \n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    np.save('superblock4.npy', image)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52495733",
   "metadata": {},
   "source": [
    "Finally, it is valuable for me to know how long it took for you to complete this task:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c73b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
