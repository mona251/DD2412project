{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5612b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def random_ortho_matrix_gen(dim_a: int, dim_b: int) -> Iterator[TensorType[\"dim_a\", \"dim_b\"]]:\n",
    "    assert dim_a >= dim_b, f\"Assuming we want projection matrices (broad and short), got dims {dim_a} x {dim_b}\"\n",
    "    while True:\n",
    "        m = ortho_group.rvs(dim=dim_a)\n",
    "        for i in range(dim_a // dim_b):\n",
    "            yield torch.Tensor(m[i*dim_b : (i+1)*dim_b])\n",
    "\n",
    "@typechecked\n",
    "def prior_sampler(name: str, batch_size: int, feature_dim: int) -> Callable[[], \n",
    "                                                                            TensorType[\"batch_size\", \"feature_dim\"]]:\n",
    "    \"\"\"\n",
    "    Constructs a sampling function from a named distribution. E.g., with `name==\"Uniform hypersphere\"`, \n",
    "    the resulting function samples `batch_size` vectors of length `feature_dim` on a uniform hypersphere.\n",
    "    \"\"\"\n",
    "    @typechecked\n",
    "    def hypersphere_sampler() -> TensorType['batch_size', 'feature_dim']:\n",
    "        X = torch.normal(mean=0, std=1, size=(batch_size, feature_dim))\n",
    "        return X / LA.norm(X, dim=1).unsqueeze(1)\n",
    "    \n",
    "    d : Dict[str,  Callable[[], TensorType[\"batch_size\", \"feature_dim\"]]] = {\n",
    "         \"Uniform hypersphere\": hypersphere_sampler, \n",
    "         \"Uniform hypercube\": lambda: torch.rand(size=(batch_size, feature_dim)),\n",
    "         \"Normal distribution\": lambda: torch.normal(mean=0, std=1, size=(batch_size, feature_dim)),\n",
    "        }\n",
    "    if name not in d:\n",
    "        raise ValueError(f\"Distr '{name}' not in {d.keys()}\")\n",
    "    \n",
    "    return d[name]\n",
    "\n",
    "class SWD_contrastiveloss(nn.Module):\n",
    "    @typechecked\n",
    "    def __init__(self, batch_size: int, feature_dim: int, prior_name: str,\n",
    "                 normalize_before_align: bool = True,\n",
    "                 SWD_dim: int=-1, SWD_lambda: float = 1.):\n",
    "        super(SWD_contrastiveloss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_dim = feature_dim\n",
    "        #self.temperature = temperature\n",
    "        self.normalize_before_align = normalize_before_align\n",
    "        self.sample_prior = prior_sampler(prior_name, batch_size=2*batch_size, feature_dim=feature_dim)\n",
    "        self.ortho_matrix_gen = random_ortho_matrix_gen(feature_dim, SWD_dim)\n",
    "        self.lmbda = SWD_lambda\n",
    "        self.SWD_dim = SWD_dim\n",
    "        \n",
    "    @typechecked\n",
    "    def forward(self, zi: TensorType[\"batch_size\", \"feature_dim\"],\n",
    "                zj: TensorType[\"batch_size\", \"feature_dim\"]):\n",
    "        # Following \"Algorithm 1\" in the paper\n",
    "        n : int = self.batch_size\n",
    "        d = zi.size(dim = -1)\n",
    "        \n",
    "        # Project zi/zj onto hypersphere (i.e. normalize).\n",
    "        if self.normalize_before_align:\n",
    "            zi = zi / LA.norm(zi, dim=1).unsqueeze(1)\n",
    "            zj = zj / LA.norm(zj, dim=1).unsqueeze(1)\n",
    "        loss_align = ((zi - zj)**2).sum() / (n*d)\n",
    "        Z : TensorType[2*self.batch_size, self.feature_dim] = torch.cat((zi, zj), dim=0).to(DEVICE)\n",
    "        P : TensorType[2*self.batch_size, self.feature_dim] = self.sample_prior().to(DEVICE)\n",
    "        W : TensorType[self.feature_dim, self.SWD_dim] = next(self.ortho_matrix_gen).to(DEVICE)\n",
    "        \n",
    "        \n",
    "        H_perp, P_perp = Z @ W, P @ W \n",
    "        #loss_distr = torch.Tensor(0.) #Getting compiler error if we do like that, solution done below.\n",
    "        loss_distr = 0 #commented out torch.Tensor since we are supposed to get a singular value anyway.\n",
    "        for j in range(self.SWD_dim):\n",
    "            hj, pj = H_perp[:, j], P_perp[:, j]\n",
    "            hj, _ = torch.sort(hj)\n",
    "            pj, _ = torch.sort(pj)\n",
    "            loss_distr = loss_distr + ((hj - pj)**2).sum()\n",
    "        loss_distr = loss_distr / (self.feature_dim * self.SWD_dim)\n",
    "        return loss_align + self.lmbda * loss_distr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
