{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2383a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from simclr import SimCLR\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from flash.core.optimizers import LARS\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from simclr.modules import NT_Xent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01080481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\Users\\TestAccount\\Desktop\\repos\\DD2412project\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7083d3f82b4a4df89ab78a60d4dc0a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\TestAccount\\Desktop\\repos\\DD2412project\\cifar-10-python.tar.gz to C:\\Users\\TestAccount\\Desktop\\repos\\DD2412project\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "batch_size = 128\n",
    "\n",
    "# To make it work in both Jupyter and standalone:\n",
    "if \"__file__\" in globals():\n",
    "    root = pathlib.Path(__file__).parent.resolve()\n",
    "else:\n",
    "    # Probably running interactively; in Jupyter, notebook path is\n",
    "    # typically 'os.getcwd()', if it's not that's where we are going\n",
    "    # to store the CIFAR data.\n",
    "    import os\n",
    "    root = pathlib.Path(os.getcwd())\n",
    "    \n",
    "    \n",
    "dataset = CIFAR10(root=root, download=True, transform = TransformsSimCLR(size = image_size))\n",
    "torch.manual_seed(43)\n",
    "train_loader = DataLoader(dataset, \n",
    "                          batch_size, \n",
    "                          shuffle=False,\n",
    "                          drop_last = True,\n",
    "                          num_workers=2,\n",
    "                          sampler = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad800d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to C:\\Users\\TestAccount/.cache\\torch\\hub\\v0.10.0.zip\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "epochs = 50\n",
    "temperature = 0.2\n",
    "projection_dim = 64\n",
    "\n",
    "encoder = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False) \n",
    "n_features = encoder.fc.in_features  # get dimensions of last fully-connected layer\n",
    "model = SimCLR(encoder, projection_dim, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "360efcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = LARS(model.parameters(), lr = 0.075 * np.sqrt(batch_size), weight_decay = 1e-6)\n",
    "criterion = NT_Xent(batch_size, temperature = temperature, world_size=1)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                       epochs, \n",
    "                                                       eta_min=0, \n",
    "                                                       last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4d43d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cab1ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Iterator, Dict\n",
    "from torch import linalg as LA\n",
    "from torchtyping import TensorType, patch_typeguard\n",
    "from typeguard import typechecked\n",
    "\n",
    "patch_typeguard()  # use before @typechecked\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "@typechecked\n",
    "def random_ortho_matrix_gen(dim_a: int, dim_b: int) -> Iterator[TensorType[\"dim_a\", \"dim_b\"]]:\n",
    "    assert dim_a >= dim_b, f\"Assuming we want projection matrices (broad and short), got dims {dim_a} x {dim_b}\"\n",
    "    while True:\n",
    "        m = ortho_group.rvs(dim=dim_a)\n",
    "        for i in range(dim_a // dim_b):\n",
    "            yield torch.Tensor(m[i*dim_b : (i+1)*dim_b])\n",
    "\n",
    "@typechecked\n",
    "def prior_sampler(name: str, batch_size: int, feature_dim: int) -> Callable[[], \n",
    "                                                                            TensorType[\"batch_size\", \"feature_dim\"]]:\n",
    "    \"\"\"\n",
    "    Constructs a sampling function from a named distribution. E.g., with `name==\"Uniform hypersphere\"`, \n",
    "    the resulting function samples `batch_size` vectors of length `feature_dim` on a uniform hypersphere.\n",
    "    \"\"\"\n",
    "    @typechecked\n",
    "    def hypersphere_sampler() -> Callable[[], TensorType[batch_size, feature_dim]]:\n",
    "        X = torch.normal(mean=0, std=1, size=(batch_size, feature_dim))\n",
    "        return X / LA.norm(X, dim=1).unsqueeze(1)\n",
    "    \n",
    "    d : Dict[str,  Callable[[], TensorType[\"batch_size\", \"feature_dim\"]]] = {\n",
    "         \"Uniform hypersphere\": hypersphere_sampler, \n",
    "         \"Uniform hypercube\": lambda: torch.rand(size=(batch_size, feature_dim)),\n",
    "         \"Normal distribution\": lambda: torch.normal(mean=0, std=1, size=(batch_size, feature_dim)),\n",
    "        }\n",
    "    if name not in d:\n",
    "        raise ValueError(f\"Distr '{name}' not in {d.keys()}\")\n",
    "    return d[name]\n",
    "\n",
    "class SWD_contrastiveloss(nn.Module):\n",
    "    @typechecked\n",
    "    def __init__(self, batch_size: int, feature_dim: int, prior_name: str,\n",
    "                 normalize_before_align: bool = True,\n",
    "                 SWD_dim: int=-1, SWD_lambda: float = 1.):\n",
    "        super(SWD_contrastiveloss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_dim = feature_dim\n",
    "        #self.temperature = temperature\n",
    "        self.normalize_before_align = normalize_before_align\n",
    "        self.sample_prior = prior_sampler(prior_name, batch_size=2*batch_size, feature_dim=feature_dim)\n",
    "        self.ortho_matrix_gen = random_ortho_matrix_gen(feature_dim, SWD_dim)\n",
    "        self.lmbda = SWD_lambda\n",
    "        \n",
    "    @typechecked\n",
    "    def forward(self, z_i: TensorType[\"batch_size\", \"feature_dim\"],\n",
    "                z_j: TensorType[\"batch_size\", \"feature_dim\"]):\n",
    "        # Following \"Algorithm 1\" in the paper\n",
    "        n : int = self.batch_size\n",
    "        d = z_i.size(dim = -1)\n",
    "        \n",
    "        # Project zi/zj onto hypersphere (i.e. normalize).\n",
    "        if self.normalize_before_align:\n",
    "            zi /= LA.norm(zi, dim=1).unsqueeze(1)\n",
    "            zj /= LA.norm(zj, dim=1).unsqueeze(1)\n",
    "        loss_align = ((zi - zj)**2).sum() / (n*d)\n",
    "        Z : TensorType[2*self.batch_size, self.feature_dim] = torch.cat((z_i, z_j), dim=0)\n",
    "        P : TensorType[2*self.batch_size, self.feature_dim] = self.sample_prior()\n",
    "        W : TensorType[self.feature_dim, self.SWD_dim] = self.ortho_matrix_gen()\n",
    "        H_perp, P_perp = Z @ W, P @ W\n",
    "        loss_distr = torch.Tensor(0.)\n",
    "        for j in range(self.SWD_dim):\n",
    "            hj, pj = H_perp[:, j], P_perp[:, j]\n",
    "            hj, _ = torch.sort(hj)\n",
    "            pj, _ = torch.sort(pj)\n",
    "            loss_distr += ((hj - pj)**2).sum()\n",
    "        loss_distr /= (self.feature_dim * self.SWD_dim)\n",
    "        return loss_align + self.lmbda * loss_distr\n",
    "    \n",
    "swd_sphere_crit = SWD_contrastiveloss(batch_size, feature_dim=64, SWD_lambda=5, SWD_dim=64, prior_name = \"Uniform hypersphere\")\n",
    "swd_normal_crit = SWD_contrastiveloss(batch_size, normalize_before_align=False, feature_dim=64, SWD_lambda=5, SWD_dim=64, prior_name = \"Normal distribution\")\n",
    "swd_cube_crit = SWD_contrastiveloss(batch_size, normalize_before_align=False, feature_dim=64, SWD_lambda=5, SWD_dim=64, prior_name = \"Uniform hypercube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def train(global_step, loader, model, criterion, optimizer, writer):\n",
    "    loss_epoch = 0\n",
    "    for steps, ((i, j), _) in enumerate(loader):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        h_i, h_j, z_i, z_j = model(i, j)\n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if steps % 50 == 0:\n",
    "            print(f\"Step [{steps}/{len(loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), global_step)\n",
    "        loss_epoch += loss.item()\n",
    "        global_step += 1\n",
    "    return loss_epoch\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss_epoch = train(global_step, train_loader, model, swd_cube_crit, optimizer, writer)\n",
    "    scheduler.step()\n",
    "    writer.add_scalar(\"Loss/train\", loss_epoch / len(loader), epoch)\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cad5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
